#Beschreibung der Datenvorverarbeitung:

Als erstes haben wir in der Datenbeschreibung überprüft, ob der Wert "NA" in den Spalten für eine bestimmte Kategorie benutzt wurde. Da haben wir festgestellt, dass es in den folgenden Spalten wirklich der Fall ist:
Sondermerkmal, Kellerzustand, Kellerhoehe, Kellerbelichtung, Kellerbereich1, Kellerbereich2, Kaminqualitaet, Poolqualitaet,Zaunqualitaet,Garagentyp,Garageninnenausbau,Garagenqualitaet,Garagenzustand.
Deswegen haben wir diese Kategorie mit "Unbekannt" ersetzt, damit sie bei der Behandlung der fehlenden Werte zu keinen Konflikten führen. 

Erster Schritt in unsere model.ipynb Datei war eine Funktion zu definieren, die die Werte in den Spalten mit den Werten in der bearbeiteteten data_description Datei vergleicht. 
So könnten wir alle Fehler wie Schreibfehler, Groß-/Kleinschreibung usw. feststellen und diese entsprechend anpassen. Danach haben wir erst die fehlenden Werte berechnet und sie wie folgt behandelt: 

Zufahrtsweg : Von 2000 Zeilen sind 1868 leer --> entfernen
Garagenbaujahr : Anzahl der Zeilen mit fehlendem 'Garagenbaujahr' und 'KeineGarage' = Anzahl der fehlende Werte in Garagenbaujahr -> Die Werte mit "0" ersetzen.
Mauerwerktyp, Mauerwerkflaeche, Wohngebiet,Versorgung,Kuechenqualitaet,Elektrik,Verkaufstyp,Funktionalitaet : mit Unbekannt ersetzen
Kellerbereichgroesse1, Kellerbereichgroesse2, KellerbereichgroesseNAu, KellerbereichgroesseGes, KellerVollbadezimmer, KellerHalbbadezimmer : Sie haben unbekannte Werte nur in den Zeilen mit dem Wert KeinKeller -> die fehlende Werte mit 0 ersetzen.
Garagenautos, Garagenflaeche : die gleiche Situation -> mit 0 ersetzen
Strassenlaenge: Mit Mittelwert ersetzen.


 
#Beschreibung des Modells:
Um unser Modell zu trainieren mussten wir die Variablen encoden. Dafür haben wir die beiden Dataframes train und test zusammengefügt, damit wir einen DateFrame erhalten, der alle Daten enthält. Um einfach und schnell zu encoden, nutzen wir die pd.get_dummies() Methode, welcher nun unseren gesamten Datensatz encodet. Danach splitten wir die Daten wieder in die unsprünglichen Datenteile auf und haben somit unsere encodeten DataFrames. Wir erstellen unsere Teil-DataFrames, mit denen wir unser Modell trainieren und evaluieren wollen, in Variablen X und Zielvariable y und trainieren einen RandomForestRegressor mithilfe von Scikit-learn auf dem gesamten Traindatensatz (1-2000) und erstelen mithilfe von unserem Modell unsere Predicitons auf dem Test-datensatz (2001-2919). Die Ergebnisse fügen wir in einen DataFrame und speichern diese in "prediction.csv". Um unsere Modellgüte zu evaluieren und abschätzen zu können, wie gut unser Modell auf den Testdaten performt, teilen wir den Test-datensatz in 80/20 auf (80 Train 20 Test) und trainieren nochmal einen RandomForestRegressor auf diesen Testdaten. Wir erstellen wieder Predicitons und geben MSE, RMSE, MAE, R2-Score und MAPE aus. Wir sehen anhand der Kennzahlen, dass unser Modell relativ gut performt auf unseren Train-Testdaten und können somit auch mit großer Wahrscheinlichkeit annehmen, dass unsere Predictions auf den Testdaten (2001-2919) auch gut sind.